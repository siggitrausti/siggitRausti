important_variables <- rownames(imp_mat)[which(imp_mat[,2] > 3)] # GINI Index...
important_variables
feat_imp_df <- importance(trauma.rf) %>%
data.frame() %>%
mutate(feature = row.names(.))
# plot dataframe
ggplot(feat_imp_df, aes(x = reorder(feature, MeanDecreaseGini),
y = MeanDecreaseGini)) +
geom_bar(stat='identity') +
coord_flip() +
theme_classic() +
labs(
x     = "Feature",
y     = "Importance",
title = "Feature Importance: <Model>"
)
rosa_train2 <- data.frame(cbind(rosa_train[,1],rosa_train[,which(colnames(rosa_train) %in% important_variables)]))
colnames(rosa_train2)[1] <- 'Death'
rosa_test2 <- data.frame(cbind(rosa_test[,1],rosa_test[,which(colnames(rosa_test) %in% important_variables)]))
colnames(rosa_test2)[1] <- 'Death'
trauma.glm <- glm(formula = Death ~.,
family = binomial(link = "logit"), data = rosa_train2)
summary(trauma.glm)
anova(trauma.glm, test="Chisq")
pR2(trauma.glm)
trauma.glm_b <- stepAIC(trauma.glm,trace = F)
summary(trauma.glm_b)
anova(trauma.glm_b, test="Chisq")
pR2(trauma.glm_b)
# Plot the AUC for ROC analysis (Measurement of classifier accuracy for binary classification)
trauma.glm <- trauma.glm_b
p <- predict(trauma.glm, newdata=rosa_test, type="response")
# Plot the AUC for ROC analysis (Measurement of classifier accuracy for binary classification)
trauma.glm <- trauma.glm_b
p <- predict(trauma.glm, newdata=rosa_train2, type="response")
pr <- prediction(p, rosa_test$Death)
prf <- ROCR::performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- ROCR::performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
default_glm_mod = train(
form = Death ~ .,
data = rosa_train2,
trControl = trainControl(method = "cv", number = 5),
method = "glm",
family = "binomial"
)
default_glm_mod$results
default_knn_mod = train(
Death ~ .,
data = rosa_train2,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(2, 20, by = 1))
)
# Predict using the GLM for the same test set
default_glm_mod = train(
form = Death ~ .,
data = rosa_test2,
trControl = trainControl(method = "cv", number = 5),
method = "glm",
family = "binomial"
)
default_glm_mod$results
prot3 <- prot4
rosa_lmm <- cbind(rosa_data_info,prot3)
rosa_lmm$ISS_group <- as.factor(rosa_lmm$ISS_group)
rosa_lmm$Death <- as.factor(rosa_lmm$Death)
source('./remove_outliers.R')
new_rosa <- data.frame(matrix(0, dim(rosa_lmm)[1], dim(rosa_lmm)[2]))
colnames(new_rosa) <- colnames(rosa_lmm)
rownames(new_rosa) <- rownames(rosa_lmm)
new_rosa[,c(1:3)] <- rosa_lmm[,c(1:3)]
for (i in 4:ncol(rosa_lmm)){
rosa_lmm_2 <- as_tibble(rosa_lmm)
colnames(rosa_lmm_2)[i] <- 'HELLO'
rosa_lmm_3 <- rosa_lmm_2[,c(1,2,3,i)]%>%
group_by(Death,ISS,ISS_group)%>%
mutate(hello= remove_outliers(HELLO))
new_rosa[,i] <- rosa_lmm_3$hello
}
new_rosa2 <- data.frame(cbind(new_rosa[,1],new_rosa[,which(colnames(new_rosa) %in% important_variables)]))
colnames(new_rosa2)[1] <- 'Death'
trauma.rf <- randomForest(Death ~ ., data=new_rosa,ntree=10000, importance=TRUE) #NOT ALL VARIABLES INCLUDED (CHECK DATASET)
imp_mat <- importance(trauma.rf)
important_variables <- rownames(imp_mat)[which(imp_mat[,2] > 3)] # GINI Index...
important_variables
new_rosa2 <- data.frame(cbind(new_rosa[,1],new_rosa[,which(colnames(new_rosa) %in% important_variables)]))
colnames(new_rosa2)[1] <- 'Death'
important_variables <- rownames(imp_mat)[which(imp_mat[,2] > 5)] # GINI Index...
important_variables
new_rosa2 <- data.frame(cbind(new_rosa[,1],new_rosa[,which(colnames(new_rosa) %in% important_variables)]))
colnames(new_rosa2)[1] <- 'Death'
trauma.glm <- glm(formula = Death ~.,
family = binomial(link = "logit"), data = new_rosa2)
new_rosa2$Death
new_rosa2$ISS
new_rosa2$Glucose
#convert training data to matrix format
x <- model.matrix(Death~.,new_rosa2)
#convert class to numerical variable
y <- ifelse(new_rosa2$Death=="1",1,0)
#perform grid search to find optimal value of lambda
#family= binomial => logistic regression, alpha=1 => lasso
# check docs to explore other type.measure options
cv.out <- cv.glmnet(x,y,alpha=1,family="binomial",type.measure = "mse" )
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
#get test data
x_test <- model.matrix(Death~.,new_rosa2)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_lse,type="response")
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(rosa_test))
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
lasso_predict[lasso_prob>.5] <- "1"
#confusion matrix
table(pred=lasso_predict,true=new_rosa2$Death)
#accuracy
mean(lasso_predict==new_rosa2$Death)
#perform grid search to find optimal value of lambda
#family= binomial => logistic regression, alpha=1 => lasso
# check docs to explore other type.measure options
cv.out <- cv.glmnet(x,y,alpha=0,family="binomial",type.measure = "mse" )
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
#get test data
x_test <- model.matrix(Death~.,new_rosa2)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_lse,type="response")
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
lasso_predict[lasso_prob>.5] <- "1"
#confusion matrix
table(pred=lasso_predict,true=new_rosa2$Death)
#accuracy
mean(lasso_predict==new_rosa2$Death)
cv.out <- cv.glmnet(x,y,alpha=1,family="binomial",type.measure = "mse" )
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
#get test data
x_test <- model.matrix(Death~.,new_rosa2)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_lse,type="response")
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
lasso_predict[lasso_prob>.5] <- "1"
#confusion matrix
table(pred=lasso_predict,true=new_rosa2$Death)
#accuracy
mean(lasso_predict==new_rosa2$Death)
# Plot the ROC curve:
perf <- ROCR::performance(pred,"tpr","fpr")
# Plot the ROC curve:
perf <- ROCR::performance(lasso_prob,"tpr","fpr")
prf
# Plot the ROC curve:
perf <- ROCR::performance(lasso_prob,"tpr","fpr")
# Plot the ROC curve:
lasso_pred <- prediction(lasso_prob,new_rosa2$Death)
perf <- ROCR::performance(lasso_pred,"tpr","fpr")
performance(lasso_pred,"auc") # shows calculated AUC for model
performance(lasso_pred,"auc") # shows calculated AUC for model
ROCR::performance(lasso_pred,"auc") # shows calculated AUC for model
auc <- ROCR::performance(lasso_pred,"auc") # shows calculated AUC for model
auc <- auc@y.values[[1]]
auc
plot(perf,colorize=FALSE, col="black") # plot ROC curve
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
default_glm_mod = train(
form = Death ~ .,
data = new_rosa2,
trControl = trainControl(method = "cv", number = 5),
method = "glm",
family = "binomial"
)
default_glm_mod$results
#plot result
plot(cv.out)
#accuracy
mean(lasso_predict==new_rosa2$Death)
lasso_prob
# TO get the cross-validation AUC:
cv.out2 <- cv.glmnet(x, y, family = "binomial",
type.measure = "auc", nfolds=5, alpha=1, nlambda = 100)
cv.out2$cvm[which(cv.out2$lambda==cv.out2$lambda.min)]
max(cv.out2)
max(cv.out2$cvm)
#perform grid search to find optimal value of lambda
#family= binomial => logistic regression, alpha=1 => lasso
# check docs to explore other type.measure options
cv.out <- cv.glmnet(x,y,alpha=1,family="binomial",type.measure = "mse",nfolds=5 )
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
#get test data
x_test <- model.matrix(Death~.,new_rosa2)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_lse,type="response")
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
lasso_predict[lasso_prob>.5] <- "1"
#confusion matrix
table(pred=lasso_predict,true=new_rosa2$Death)
#accuracy
mean(lasso_predict==new_rosa2$Death)
# TO get the cross-validation AUC:
cv.out2 <- cv.glmnet(x, y, family = "binomial",
type.measure = "auc", nfolds=5, alpha=1, nlambda = 100)
cv.out2$cvm[which(cv.out2$lambda==cv.out2$lambda.min)]
#accuracy
mean(lasso_predict==new_rosa2$Death)
# Plot the ROC curve:
lasso_pred <- prediction(lasso_prob,new_rosa2$Death)
perf <- ROCR::performance(lasso_pred,"tpr","fpr")
auc <- ROCR::performance(lasso_pred,"auc") # shows calculated AUC for model
auc <- auc@y.values[[1]]
auc
plot(perf,colorize=FALSE, col="black") # plot ROC curve
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
# Plot the ROC curve:
lasso_pred <- prediction(lasso_prob,new_rosa2$Death)
perf <- ROCR::performance(lasso_pred,"tpr","fpr")
auc <- ROCR::performance(lasso_pred,"auc") # shows calculated AUC for model
auc <- auc@y.values[[1]]
auc
plot(perf,colorize=FALSE, col="black") # plot ROC curve
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
lasso_prob
lambda_lse
colnames(new_rosa2)
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
#perform grid search to find optimal value of lambda
#family= binomial => logistic regression, alpha=1 => lasso
# check docs to explore other type.measure options
cv.out <- cv.glmnet(x,y,alpha=1,family="binomial",type.measure = "mse")
#plot result
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_lse <- cv.out$lambda.1se
coef(cv.out,s=lambda_lse)
heyhey  <- coef(cv.out,s=lambda_lse)
heyhey
heyhey[[1]]
heyhey[1
]
heyhey[2]
heyhey[3]
heyhey[[1]]
heyhey[3
heyhey[3]
heyhey[3]
heyhey[4]
heyhey[5]
heyhey[6]
str(heyhey)
heyhey$x
heyhey[[x]]
cv.out$glmnet.fit
cv.out$cvsd
cv.out$cvm
mean(cv.out$cvm)
cv.out$lambda
#accuracy
mean(lasso_predict==new_rosa2$Death)
heyhey
heyhey[[[1]]]
inds<-which(heyhey!=0)
variables<-row.names(heyhey)[inds]
variables<-variables[variables %ni% '(Intercept)']
variables<-variables[variables %in% '(Intercept)']
`%ni%`<-Negate(`%in%')
#get test data
x_test <- model.matrix(Death~.,new_rosa2)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_lse,type="response")
#translate probabilities to predictions
lasso_predict <- rep("0",nrow(new_rosa2))
lasso_predict[lasso_prob>.5] <- "1"
#confusion matrix
table(pred=lasso_predict,true=new_rosa2$Death)
#accuracy
mean(lasso_predict==new_rosa2$Death)
# Plot the ROC curve:
lasso_pred <- prediction(lasso_prob,new_rosa2$Death)
perf <- ROCR::performance(lasso_pred,"tpr","fpr")
auc <- ROCR::performance(lasso_pred,"auc") # shows calculated AUC for model
auc <- auc@y.values[[1]]
auc
plot(perf,colorize=FALSE, col="black") # plot ROC curve
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
# Plot the AUC for ROC analysis (Measurement of classifier accuracy for binary classification)
trauma.glm <- trauma.glm_b
p <- predict(trauma.glm, newdata=rosa_train2, type="response")
pr <- prediction(p, rosa_test$Death)
prf <- ROCR::performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- ROCR::performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
# AUC of 0.87 (when using all data for all data)
# I need to add some cross-validation step, where the set is split into train and test X times etc.
library(caret)
default_glm_mod = train(
form = Death ~ .,
data = new_rosa2,
trControl = trainControl(method = "cv", number = 5),
method = "glm",
family = "binomial"
)
default_glm_mod$results
default_knn_mod = train(
Death ~ .,
data = rosa_train2,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(2, 20, by = 1))
)
default_knn_mod
head(default_knn_mod$results, 7)
ggplot(default_knn_mod) + theme_bw()
default_knn_mod$bestTune
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(default_knn_mod)
# Predict using the GLM for the same test set
default_glm_mod = train(
form = Death ~ .,
data = rosa_test2,
trControl = trainControl(method = "cv", number = 5),
method = "glm",
family = "binomial"
)
default_glm_mod$results
# Turns out, the best accuracy I can get, is from either glm or KNN
# Accuracy (GLM) = 0.76 +/- 0.08 with the randomForest feature selection (GINI)
# Accuracy (KNN) = 0.78 +/- 0.09 with the randomForest feature selection (GINI)
# Accuracy (GLM) = 0.78 +/- 0.1 with the PLS-DA feature selection
# Accuracy (KNN) = 0.76 +/- 0.09 with the PLS-DA feature selection
# Does the metabolite-prediction perform better than ISS score alone?
trauma.glm1 <- glm(formula = Death ~ ISS, family = binomial(link = "logit"), data = new_rosa)
summary(trauma.glm1)
pR2(trauma.glm1)
p1 <- predict(trauma.glm1, newdata=new_rosa, type="response")
pr1 <- prediction(p1, new_rosa$Death)
prf1 <- ROCR::performance(pr1, measure = "tpr", x.measure = "fpr")
plot(prf1)
auc1 <- ROCR::performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc1
# Why yes, yes it does. (0.64 here vs 0.88 in the other), in addition to more variance being explained in
# the other (0.37 vs 0.05 (McFadden)) and this is before cross-validation.
# PERHAPS, THE BEST WAY OF FINDING THE VARIABLES TO USE FOR PREDICTIONS, IS TO USE THE FIRST DATA (WITH
# ALL THE METADATA) TO CORRECT FOR EFFECTS OF OTHER VARIABLES (SEX, ADRENALINE ETC), AND FIND WHICH METABOLITES
# COULD BE USEFUL IN PREDICTING THE SURVIVAL OF PATIENTS.
# ------------------------------------------ STEPS FOR STABILIZING VARIANCE FOR PLOTTING --------------------------
# Perform multiple regression analysis, and create a new dataframe:
rosa_lmm <- new_rosa
rosa_lmm2 <- rosa_lmm
for (i in 4:ncol(rosa_lmm)){
fitMet_test <- glm(rosa_lmm[,i] ~ ISS,data=rosa_lmm)
rosa_lmm2[,i] <- predict(fitMet_test, newdata=cbind(rosa_lmm[,c(1:3)],rosa_lmm[,i]))
}
id_mets_list <- which(colnames(rosa_lmm) %in% ft)
source('./boxMets.R')
blue2 <- boxMets(rosa_lmm,id_mets = 4:9,'Death','ISS_group')
blue2
blue2 <- boxMets(rosa_lmm2,id_mets = 10:15,'ISS_group','ISS_group')
blue2
# PCA:
rosa_4 <- cbind(ISS = as.factor(rosa_lmm2$ISS_group),Dummy = rep(0,nrow(rosa_lmm2)),rosa_lmm2[,4:ncol(rosa_lmm2)])
metPCA(rosa_4,groups = "ISS",colors=ColBrew("JCO"),pc=c(1,2),center=T) + ggtitle('PCA after LMM')
# PLS_DA:
dat = as.matrix(rosa_lmm2[,-c(1:3)])
vac.plsda <- mixOmics::plsda(dat, Y=rosa_lmm2$ISS_group, ncomp=3)
mixOmics::plotIndiv(vac.plsda,legend=T,title='PLS-DA after LMM',ellipse=T,col=ColBrew('JCO')[1:3])
#ggsave('After_LMM_PLSDA_ROSA_291019.png',width = 6, height = 6, units = "in")
# Now plot the original PLS-DA:
dat_orig <- as.matrix(rosa_lmm[,-c(1:3)])
vac.plsda.orig <- mixOmics::plsda(dat_orig, Y=rosa_lmm$ISS_group, ncomp=3)
mixOmics::plotIndiv(vac.plsda.orig,legend=T,title='PLS-DA before LMM',ellipse=T,col=ColBrew('JCO')[1:3])
# ------------------------------- PERFORM CORRELATION ANALYSIS --------------------------------
# Create a cor-mat of the trauma data:
cor_vals <- rep(0,length(rosa_lmm)-3)
cor_p_vals <- rep(0,length(rosa_lmm)-3)
for (i in 4:ncol(rosa_lmm)){
res <- cor.test(rosa_lmm$ISS, rosa_lmm[,i],
method = "spearman",exact=F)
cor_p_vals[i-3] <- res$p.value
cor_vals[i-3] <- res$estimate
}
#cor_p_vals <- p.adjust(cor_p_vals,method='BH',n=length(cor_p_vals))
met_stat_corr <- colnames(rosa_lmm)[which(cor_p_vals < 0.01)+3]
cor_vals_mets <- cor_vals[which(cor_p_vals < 0.01)]
cor_p_vals_mets <- cor_p_vals[which(cor_p_vals < 0.01)]
met_data <- data.frame(cbind(mets = met_stat_corr,corvals = cor_vals_mets,pvals = cor_p_vals_mets))
# ------------------------------- READ IN THE 20-PATIENT DATA --------------------------------
# Read in data:
cases <- read_excel('Complete data file.xlsx','cases','A1:AA67')
controls <- read_excel('Complete data file.xlsx','controls','A1:AA67')
metadata <- read_excel('Clinical data.xlsx','Sheet1','A1:AW21')
col_names <- cases$`Metabolite name`
cases2 <- data.frame(t(cases))
colnames(cases2) <- col_names
cases2 <- cases2[-c(1:3),]
rownames(cases2) <- cases2$PAIR_ID
cases2 <- cases2[,-c(1)]
id_select <- c()
id_takeout <- c()
for (i in 1:length(rownames(cases2))){
id_cand <- which(metadata$PatientID %in% rownames(cases2)[i])
if (length(id_cand) != 0){
id_select <- c(id_select,id_cand)
} else {
id_takeout <- c(id_takeout,i)
}
}
cases2 <- cases2[-id_takeout,]
names_i_want <- rownames(cases2)
cases2 <- apply(cases2, 2, as.numeric)
cases2 <- data.frame(cases2)
rownames(cases2) <- names_i_want
cases3 <- data.frame(cbind(metadata[id_select,c(4,5,13,24,44,45,46,47,48,49)],cases2))
cases3$Gender0female1male <- as.factor(cases3$Gender0female1male)
# Perform multiple regression analysis, and create a new dataframe:
cases_fin <- cases3
for (i in 11:ncol(cases3)){
fitMet_test <- glm(cases3[,i] ~ Gender0female1male+Ageyears+Adrenalin0H,data=cases3)
cases_fin[,i] <- predict(fitMet_test, newdata=cbind(cases3[,c(1:10)],cases3[,i]))
}
# WHAT I WANT TO DO: TEST ALL MODEL VARIABLES, DO THE STEPAIC BACKWARDS AND ELIMINATE THE NON-ESSENTIAL STUFF
library(mgcv)
library(car)
library(MASS)
jojo <- lm(cases3[,15] ~ ISS + Syndecan10H + Adrenalin0H + Noradrenalin0H + Gender0female1male +
Ageyears + TotalFluidsPrebaselineCrystalloid + sVEcadherin0H,data=cases3)
# FIRST, IDENTIFY THE METADATA INFORMATION THAT IS ASSOCIATED WITH THE ISS SCORE:
demographic_data <- cases3[,1:10]
demographic_model <- lm(ISS~ ., data=demographic_data)
#BEFORE DOING THE STEPWISE-AIC BAWCKWARD ELIMINTATION, I SHOULD CHECK THE PREDICTORS FOR COLINEARITY. THAT WAY, I
# CAN DELETE THE NON-EXPLAININ VARIABLES FROM THE DATA (LIKE AGE AND EXPERIENCE WOULD BE CORRELATED, INCLUDING BOTH
# IN THE MODEL WOULD BE REDUNDANT)
par(mfrow=c(2,2))
plot(demographic_model)
summary(demographic_model)
install.packages('mctest')
variables<-row.names(heyhey)[inds]
variables<- variables[-which(variables) == '(Intercept)']
variables<- variables[-which(variables == '(Intercept)')]
variables
source('./boxMets.R')
id_mets_list <- which(colnames(new_rosa) %in% variables)
source('./boxMets.R')
blue2 <- boxMets(new_rosa,id_mets = id_mets_list[1:6],'Death','Death')
new_rosa$Death
blue2 <- boxMets(new_rosa,id_mets = id_mets_list[1:6],'Death','Death')
new_rosa$ISS
new_rosa$ISS_group
new_rosa$Acetylcarnitine
blue2 <- boxMets(new_rosa,id_mets = id_mets_list[1:3],'Death','Death')
detach("package:randomForest", unload=TRUE)
id_mets_list <- which(colnames(new_rosa) %in% variables)
source('./boxMets.R')
blue2 <- boxMets(new_rosa,id_mets = id_mets_list[1:3],'Death','Death')
blue2
blue2 <- boxMets(new_rosa,id_mets = id_mets_list[1:6],'Death','Death')
blue2
install.packages("glmnet")
library(roxygen2)
setwd("E:/Dropbox/R_Dropbox/siggitRausti")
library(roxygen2)
list.files()
library(devtools)
install_github('siggitrausti/siggitRausti')
setwd("E:/Dropbox/R_Dropbox")
library(siggitRausti)
setwd("E:/Dropbox/R_Dropbox/siggitRausti")
library(devtools)
devtools::document()
install_github('siggitrausti/siggitRausti')
setwd("E:/Dropbox/R_Dropbox")
library(devtools)
install_github('siggitrausti/siggitRausti')
library(siggitRausti)
library(devtools)
setwd("E:/Dropbox/R_Dropbox/siggitRausti")
document()
